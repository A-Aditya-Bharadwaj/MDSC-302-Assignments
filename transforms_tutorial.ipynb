{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms \n",
    "- We use **transforms** to perform some manipulation of the data and make it suitable for training\n",
    "- All Torch Vision datasets have two parameters\n",
    "    - `transform`: to modify the features and,\n",
    "    - `target_transform`: to modify the labels, accept callables containing the transformation logic.\n",
    "- The [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html) module offers several commonly-used transforms out of the box.\n",
    "- The FashionMNIST features are in PIL Image format, and the labels are integers.\n",
    "- For training, we need the features as normalized tensors, and the labels as one-hot encoded tensors.\n",
    "- To make tese transformation, we use `ToTensor` and `Lambda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = True,\n",
    "    download = False,\n",
    "    transform = ToTensfor(),\n",
    "    target_transform = Lambda(lambda y: torch.zeros(10, dtype = torch.float).scatter_(0, torch.tensor(y), value = 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ds = datasets.FashionMNIST ` This line creates an instance of the FashionMNIST dataset.\n",
    "\n",
    "`root=\"data\"`: This specifies the directory where the dataset will be downloaded and saved.\n",
    "\n",
    "`train=True`: This specifies that the dataset should be the training set.\n",
    "\n",
    "`download=False`: This specifies that the dataset should not be downloaded if it is not already available in the specified root directory.\n",
    "\n",
    "`transform=ToTensor()`: This specifies the transformation to be applied to the dataset's features. The `ToTensor()` transformation converts the images from PIL images to PyTorch tensors.\n",
    "\n",
    "`target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))`: This specifies the transformation to be applied to the dataset's targets (labels). The Lambda transformation allows the application of a custom lambda function. In this case, the lambda function converts the target label y into a one-hot encoded tensor. It creates a zero tensor of shape (10,) and then sets the value at the index corresponding to the label y to 1.\n",
    "\n",
    ".`scatter_(0, torch.tensor(y), value=1)` applies the `scatter_()` operation on the tensor along dimension 0. Here's what each argument does:\n",
    "- 0 specifies the dimension along which to scatter the values. In this case, it's dimension 0, which corresponds to the indices of the one-hot encoded tensor.\n",
    "- `torch.tensor(y)` provides the indices where the non-zero values should be placed. The y variable represents the label value, and `torch.tensor(y)` converts it to a PyTorch tensor.\n",
    "- value=1 indicates the value to be scattered at the specified indices. In this case, it's 1, meaning that the corresponding indices will have a value of 1 in the resulting tensor.\n",
    "\n",
    "By creating this FashionMNIST dataset object, you can access and use the dataset for training or evaluation. The dataset's features will be tensors, and the targets will be one-hot encoded tensors, as specified by the transformations."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
