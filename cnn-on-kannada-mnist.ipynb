{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-16T04:59:23.137457Z","iopub.execute_input":"2023-09-16T04:59:23.138250Z","iopub.status.idle":"2023-09-16T04:59:23.543028Z","shell.execute_reply.started":"2023-09-16T04:59:23.138201Z","shell.execute_reply":"2023-09-16T04:59:23.542049Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/Kannada-MNIST/sample_submission.csv\n/kaggle/input/Kannada-MNIST/Dig-MNIST.csv\n/kaggle/input/Kannada-MNIST/train.csv\n/kaggle/input/Kannada-MNIST/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import the libraries\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader,Dataset\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:59:23.546732Z","iopub.execute_input":"2023-09-16T04:59:23.547168Z","iopub.status.idle":"2023-09-16T04:59:25.304139Z","shell.execute_reply.started":"2023-09-16T04:59:23.547138Z","shell.execute_reply":"2023-09-16T04:59:25.303066Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load the data\ntrain_data = pd.read_csv(\"/kaggle/input/Kannada-MNIST/train.csv\")\nvalid_data = pd.read_csv(\"/kaggle/input/Kannada-MNIST/Dig-MNIST.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:59:25.305614Z","iopub.execute_input":"2023-09-16T04:59:25.306409Z","iopub.status.idle":"2023-09-16T04:59:30.557861Z","shell.execute_reply.started":"2023-09-16T04:59:25.306370Z","shell.execute_reply":"2023-09-16T04:59:30.556654Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class KannadaMNIST(Dataset):\n    def __init__(self,data):\n        self.data = data\n        self.img_labels = self.data.iloc[:,0]\n        self.img = self.data.iloc[:,1:]\n        \n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self,idx):\n        image = self.img.iloc[idx,:].values.reshape(1,28,28)\n        label = self.img_labels.iloc[idx]\n        return image,label","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:59:30.561137Z","iopub.execute_input":"2023-09-16T04:59:30.561543Z","iopub.status.idle":"2023-09-16T04:59:30.568577Z","shell.execute_reply.started":"2023-09-16T04:59:30.561506Z","shell.execute_reply":"2023-09-16T04:59:30.567413Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_dataset = KannadaMNIST(train_data)\nvalid_dataset = KannadaMNIST(valid_data)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:59:30.570320Z","iopub.execute_input":"2023-09-16T04:59:30.571216Z","iopub.status.idle":"2023-09-16T04:59:30.583918Z","shell.execute_reply.started":"2023-09-16T04:59:30.571142Z","shell.execute_reply":"2023-09-16T04:59:30.582907Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"batch_size=64\ntrain_dataloader = DataLoader(train_dataset,batch_size = batch_size,shuffle = True)\nvalid_dataloader = DataLoader(valid_dataset,batch_size = batch_size,shuffle = True)\na,b = next(iter(train_dataloader))\na.data.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:59:30.585918Z","iopub.execute_input":"2023-09-16T04:59:30.586341Z","iopub.status.idle":"2023-09-16T04:59:30.616886Z","shell.execute_reply.started":"2023-09-16T04:59:30.586306Z","shell.execute_reply":"2023-09-16T04:59:30.615854Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"torch.Size([64, 1, 28, 28])"},"metadata":{}}]},{"cell_type":"code","source":"class MNISTConvNet(nn.Module):\n    def __init__(self):\n        super(MNISTConvNet, self).__init__()\n        self.conv1 = nn.Sequential(\n        nn.Conv2d(1, 32, 5, padding='same'),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n    )\n        self.conv2 = nn.Sequential(\n        nn.Conv2d(32, 64, 5, padding='same'),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n    )\n        self.fc1 = nn.Sequential(\n        nn.Flatten(),\n        nn.Linear(3136, 1024),\n        nn.Dropout(0.5),\n        nn.Linear(1024, 10)\n    )\n    def forward(self, x):\n        x = x.float()\n        x = self.conv1(x)\n        x = self.conv2(x)\n        return self.fc1(x)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:59:30.620459Z","iopub.execute_input":"2023-09-16T04:59:30.620795Z","iopub.status.idle":"2023-09-16T04:59:30.631012Z","shell.execute_reply.started":"2023-09-16T04:59:30.620768Z","shell.execute_reply":"2023-09-16T04:59:30.629718Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MNISTConvNet().to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:59:30.632795Z","iopub.execute_input":"2023-09-16T04:59:30.633529Z","iopub.status.idle":"2023-09-16T04:59:32.254564Z","shell.execute_reply.started":"2023-09-16T04:59:30.633492Z","shell.execute_reply":"2023-09-16T04:59:32.253620Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"MNISTConvNet(\n  (conv1): Sequential(\n    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=same)\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc1): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=3136, out_features=1024, bias=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=1024, out_features=10, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"lr = 0.001\nnum_epochs = 20\n\nloss_fn = nn.CrossEntropyLoss()\noptimizer=optim.AdamW(model.parameters(),lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T04:59:46.055541Z","iopub.execute_input":"2023-09-16T04:59:46.055958Z","iopub.status.idle":"2023-09-16T04:59:46.061678Z","shell.execute_reply.started":"2023-09-16T04:59:46.055927Z","shell.execute_reply":"2023-09-16T04:59:46.060453Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"for epochs in range(num_epochs):\n    running_loss = 0.0\n    num_correct = 0\n    for inputs, labels in train_dataloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = loss_fn(outputs, labels)\n        loss.backward()\n        running_loss += loss.item()\n        optimizer.step()\n        _, idx = outputs.max(dim=1)\n        num_correct += (idx == labels).sum().item()\nprint('Loss: {} Accuracy: {}'.format(running_loss/len(train_dataloader),\n                                 num_correct/len(train_dataloader)))","metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:05:25.435783Z","iopub.execute_input":"2023-09-16T05:05:25.436238Z","iopub.status.idle":"2023-09-16T05:08:48.803781Z","shell.execute_reply.started":"2023-09-16T05:05:25.436204Z","shell.execute_reply":"2023-09-16T05:08:48.802652Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Loss: 0.1030041851500137 Accuracy: 63.65138592750533\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}